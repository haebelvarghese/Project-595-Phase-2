# Project-595-Phase-2
Neuromorphic computing

Abstract
Spiking Neural Networks on neuromorphic hardware have a lot of advantages, hence it is used for efficient implementation of deep neural networks. But as we design more complex deep neural networks, we need to find better methods to reduce the storage size and the time required for computing. In this paper we are using the model compression technique to optimize our SNN. We are hence designing an algorithm-hardware co-optimization framework that will improve the hardware usage and at the same time keep the accuracy of the neural network high.

Problem Description
The team aims to study and produce a framework that optimizes Spiking Neural Network (SNN) by utilizing model compression techniques including weight pruning and weight quantization considering the simulation of such neural network is very power hungry. In adidtion to such optimization, a major goal of such framework is the ability to transform an optimized SNN to an actual hardware based simulation using components specifically designed for different neural networks. The team believes that the optimization of SNN and ability to transform software design to hardware design within the same framework will help advance the research and development of SNN related hardwares and broaden SNN driven applications.

The team has two groups studying two aspects of the problem: software and hardware. On the software side, the focus is on implementing and optimizing a given SNN model with model compression techniques mentioned above. Furthermore, a visualizer that helps understand the network topology is to be developed.
